{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from image_ops import load_and_resize, preprocess_im, pil_bgr_to_rgb, combine_image_and_heatmap, combine_horz\n",
    "from similarity_ops import compute_spatial_similarity\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1 = 'faces'\n",
    "type2 = 'hotels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyas/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/shreyas/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/shreyas/anaconda3/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=True).eval()\n",
    "\n",
    "# Get your input\n",
    "img1 = read_image(type1 + \"1.jpg\")\n",
    "img2 = read_image(type2 + \"2.jpg\")\n",
    "\n",
    "# Preprocess\n",
    "img1_norm = normalize(resize(img1, (224, 224)) / 255., [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "img2_norm = normalize(resize(img2, (224, 224)) / 255., [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.nn.Sequential(*list(model.children())[:-2])  \n",
    "features1 = f(img1_norm.unsqueeze(0))\n",
    "features2 = f(img2_norm.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, h, w = features1.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the similarity heatmap\n",
    "conv1 = features1.squeeze(0).permute(1, 2, 0).detach().numpy().reshape(h*w, c)\n",
    "conv2 = features2.squeeze(0).permute(1, 2, 0).detach().numpy().reshape(h*w, c)\n",
    "similarity = compute_spatial_similarity(conv1, conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity1, similarity2 = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00230161, 0.00375747, 0.00388819, 0.0057789 , 0.00650663,\n",
       "        0.00912857, 0.00840714],\n",
       "       [0.0036832 , 0.00643441, 0.00661743, 0.00961917, 0.01025735,\n",
       "        0.01443241, 0.01251629],\n",
       "       [0.00540263, 0.00750655, 0.00594269, 0.00773212, 0.00922846,\n",
       "        0.01459241, 0.01406103],\n",
       "       [0.00732416, 0.00944719, 0.00692369, 0.00806311, 0.00925338,\n",
       "        0.01417573, 0.01366571],\n",
       "       [0.00891512, 0.01091807, 0.00905613, 0.00905808, 0.0084312 ,\n",
       "        0.0113091 , 0.01077592],\n",
       "       [0.0099806 , 0.01516167, 0.02008093, 0.02404412, 0.02107863,\n",
       "        0.01740684, 0.0108393 ],\n",
       "       [0.00839548, 0.01214599, 0.01583638, 0.01941086, 0.01781347,\n",
       "        0.0133991 , 0.00804534]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_path = type1 + \"1.jpg\"\n",
    "img2_path = type2 + \"2.jpg\"\n",
    "\n",
    "# Load the images\n",
    "img1_arr = load_and_resize(img1_path)\n",
    "img2_arr = load_and_resize(img2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_out = combine_image_and_heatmap(img1_arr, similarity1)\n",
    "img2_out = combine_image_and_heatmap(img2_arr, similarity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_final = combine_horz([img1_out, img2_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_final_pil = Image.fromarray(np.uint8(sim_final))\n",
    "sim_bgr2rgb = pil_bgr_to_rgb(sim_final_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_path = \"sim_{}_{}.jpg\".format(type1, type2)\n",
    "sim_bgr2rgb.save(sim_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
