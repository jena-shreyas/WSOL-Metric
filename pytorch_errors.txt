1) NameError: name '_C' is not defined
Sol : factory resetting the runtime and then rerunning the import without any changes

2) nvcc --version works but nvidia-smi gives "not installed"
Sol : 

	Run the following commands to remove everything NVIDIA, and then install the NVIDIA drivers : 

	    1. sudo apt install --reinstall gcc
 	    2. sudo apt-get --purge -y remove 'nvidia*'
	    3. sudo apt install nvidia-driver-525 (or any other new version) 
	    4. sudo reboot
	    
	Next, you'll see nvidia-smi work but nvcc --version stops working. This is bcoz nvidia-cuda-toolkit was deleted, which is needed for CUDA to run.
	
	Now, install nvidia-cuda-toolkit using :
	
	    sudo apt install nvidia-cuda-toolkit
	    
	Hopefully, both nvidia-smi and nvcc --version will work after that.


3) How to distribute code across multiple GPUs using nn.DataParallel ?

Sol :

	Setup the model in the following manner :
	
	device_ids = [0, 1]			# specifies the list of GPUs that you'll use

	model = resnet18(pretrained=True)
	model = nn.DataParallel(model, device_ids=device_ids)	# pass the GPU list to the DataParallel method
	
	# next, by convention, all tensors and model itself must be dumped on the first device in the list, which acts as a staging area - it distibutes the load to other GPUs and accumulates their results and sends it back.
	
	model.to(f'cuda:{device_ids[0]}')
	
	Now, for any input tensor passed to the model, dump it to the 0th device as well :	
	input_tensor.to(f'cuda:{device_ids[0]}')		
	
	
